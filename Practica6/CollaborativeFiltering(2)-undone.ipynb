{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://www.ubu.es/sites/default/files/portal_page/images/logo_color_2l_dcha.jpg\" height=\"150\" width=\"150\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Collaborative Filtering (2)\n",
    "[Nacho Santos](www.nacho.santos.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en las dimensiones:\n",
      "Dimensiones de Y: (1682, 943) - Esperadas: (943, 1682)\n",
      "Dimensiones de R: (1682, 943) - Esperadas: (943, 1682)\n",
      "Matriz Y:\n",
      "[[5. 4. 0. 0. 4.]\n",
      " [3. 0. 0. 0. 3.]\n",
      " [4. 0. 0. 0. 0.]\n",
      " [3. 0. 0. 0. 0.]\n",
      " [3. 0. 0. 0. 0.]]\n",
      "\n",
      "Matriz R:\n",
      "[[1. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Other functions necessary for this assignment\n",
    "# The python file \"recommender_system.py\" must be in the same folder as this notebook, otherwise,\n",
    "# you have to add the path to the file\n",
    "from recommender_system import *\n",
    "\n",
    "# Ruta al archivo 'u.data' en tu carpeta de trabajo de Jupyter\n",
    "file_path_ratings = 'u.data'\n",
    "\n",
    "# Leer el archivo 'u.data' y crear las matrices \"Y\" y \"R\"\n",
    "ratings_data = np.genfromtxt(file_path_ratings, delimiter='\\t', dtype=int)\n",
    "num_users = np.max(ratings_data[:, 0])\n",
    "num_movies = np.max(ratings_data[:, 1])\n",
    "\n",
    "dim_Y = (num_users, num_movies)\n",
    "dim_R = (num_users, num_movies)\n",
    "\n",
    "# Supongamos que estas son las matrices cargadas\n",
    "Y = np.load('matriz_Y.npy')\n",
    "R = np.load('matriz_R.npy')\n",
    "\n",
    "# Verificar las dimensiones de las matrices Y y R\n",
    "if Y.shape == dim_Y and R.shape == dim_R:\n",
    "    print(\"Las dimensiones son correctas:\")\n",
    "    print(f\"Dimensiones de Y: {Y.shape} - Esperadas: {dim_Y}\")\n",
    "    print(f\"Dimensiones de R: {R.shape} - Esperadas: {dim_R}\")\n",
    "else:\n",
    "    print(\"Error en las dimensiones:\")\n",
    "    print(f\"Dimensiones de Y: {Y.shape} - Esperadas: {dim_Y}\")\n",
    "    print(f\"Dimensiones de R: {R.shape} - Esperadas: {dim_R}\")\n",
    "    \n",
    "# Imprimir una muestra de las matrices Y y R\n",
    "print(\"Matriz Y:\")\n",
    "print(Y[:5, :5])  # Imprime las primeras 5 filas y 5 columnas de Y\n",
    "\n",
    "print(\"\\nMatriz R:\")\n",
    "print(R[:5, :5])  # Imprime las primeras 5 filas y 5 columnas de R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# This line is necessary to show matplotlib plots inside the jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2 The cost funcion J and the gradient of J\n",
    "The objective of this point is to build a function to compute the cost J and the corresponding gradient of J. In particular, you are going to implement a function called **cofiCostFunc()** with the arguments(inputs) and outputs detailed below (the code of the function is partially predefined in a cell right after).\n",
    "\n",
    "**Arguments** (in this order)\n",
    "* *parameters* (the paramaters of the cost function, i.e. X and $\\theta$\n",
    "* *Y* (matrix of ratings)\n",
    "* *R* (matrix of watched movies)\n",
    "* *n_users* (number of users)\n",
    "* *n_movies* (number of movies)\n",
    "* *n_characteristics* (number of the filter characteristics)\n",
    "* *landa* (regularization parameter)\n",
    "\n",
    "**Outputs** (in this order)\n",
    "* *cost* (value of the cost function J)\n",
    "* *gradient* (gradient of the cost function J)\n",
    "* La función cofiCostFunc que proporcioné anteriormente encapsula la fórmula en un bloque de código en Python. La fórmula se implementa paso a paso dentro de la función. A continuación, te muestro cómo cada parte de la fórmula se traduce en el código:\n",
    "\n",
    "    Error Cuadrático:\n",
    "        predictions = X.dot(Theta.T) calcula todas las predicciones de las calificaciones como el producto punto entre las características de las películas XX y las preferencias del usuario ΘΘ.\n",
    "        errors = (predictions - Y) * R calcula la diferencia entre las predicciones y las calificaciones reales YY, pero solo para los elementos donde RR es igual a 1 (es decir, donde una calificación existe).\n",
    "\n",
    "    Costo sin Regularización:\n",
    "        cost = (1/2) * np.sum(errors**2) calcula la mitad de la suma de los errores cuadráticos, que es la primera parte de la fórmula.\n",
    "\n",
    "    Regularización:\n",
    "        cost += (lambda_reg/2) * (np.sum(Theta**2) + np.sum(X**2)) añade la regularización para ΘΘ y XX al costo, que es la suma de la mitad del término de regularización multiplicado por la suma de los cuadrados de los elementos de ΘΘ y XX.\n",
    "\n",
    "    Gradientes:\n",
    "        X_grad = errors.dot(Theta) + lambda_reg * X calcula el gradiente para XX con regularización.\n",
    "        Theta_grad = errors.T.dot(X) + lambda_reg * Theta calcula el gradiente para ΘΘ con regularización.\n",
    "\n",
    "    Vector de Gradientes:\n",
    "        gradient = np.concatenate([X_grad.ravel(), Theta_grad.ravel()]) aplana y concatena los gradientes de XX y ΘΘ en un solo vector para su uso en algoritmos de optimización.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Cost and gradient function\n",
    "def cofiCostFunc(parameters, Y, R, n_users, n_movies, n_features, lamb):\n",
    "    # parameters: vector with the matrices X and Theta folded\n",
    "    # Y: matrix of ratings\n",
    "    # R: matrix of watched movies\n",
    "    # n_users: number of users (number of columns of the matrix Y)\n",
    "    # n_movies: number of movies (number of rows of the matrix Y)\n",
    "    # n_features: number of movies' features (a parameter of the CF algorithm)\n",
    "    # lamb: regularization term\n",
    "    #\n",
    "    # cofiCostFunc returns the cost J and the gradient of J\n",
    "\n",
    "    # You need to return the following values correctly\n",
    "    cost = 0\n",
    "    gradient = np.zeros_like(parameters)\n",
    "    \n",
    "    # Desplegar X y Theta de parameters\n",
    "    X = parameters[:n_movies * n_features].reshape(n_movies, n_features)\n",
    "    Theta = parameters[n_movies * n_features:].reshape(n_users, n_features)\n",
    "    \n",
    "    # Calcular las predicciones de las calificaciones\n",
    "    predictions = X.dot(Theta.T)\n",
    "    \n",
    "    # Calcular los errores solo para las películas que han sido calificadas\n",
    "    errors = (predictions - Y) * R\n",
    "    \n",
    "    # Calcular el coste con regularización\n",
    "    cost = 0.5 * np.sum(errors ** 2) + (lamb / 2) * (np.sum(Theta ** 2) + np.sum(X ** 2))\n",
    "    \n",
    "    # Calcular los gradientes con regularización\n",
    "    X_grad = errors.dot(Theta) + lamb * X\n",
    "    Theta_grad = errors.T.dot(X) + lamb * Theta\n",
    "    \n",
    "    # Replegar los gradientes en un solo vector\n",
    "    gradient = np.concatenate([X_grad.ravel(), Theta_grad.ravel()])\n",
    "    \n",
    "    return cost, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1 Input *parameters* of the cofiCostFunc\n",
    "\n",
    "**Features X and preferences Theta**\n",
    "\n",
    "The Collaborative Filtering (CF) algorithm is based on two sets of lineas regressions, the first one corresponds to the movies' features X, and the second one corresponds to the users' preferences Theta. Assuming n features, the matrix X will be:\n",
    "\n",
    "$$X=\\begin{bmatrix}x^{(1)}_{1} & ...& x^{(1)}_{n} \\\\. & ...& .\\\\x^{(m)}_{1} & ...& x^{(m)}_{n} \\end{bmatrix}$$\n",
    "\n",
    "where the i-th row of X corresponds to the feature vector $x^{(i)}$ for the i-th movie.\n",
    "\n",
    "And the matrix Theta will be:\n",
    "\n",
    "$$Theta=\\Theta=\\begin{bmatrix}\\theta^{(1)}_{1} & ...& \\theta^{(1)}_{n} \\\\. & ...& .\\\\\\theta^{(u)}_{1} & ...& \\theta^{(u)}_{n} \\end{bmatrix}$$\n",
    "\n",
    "where the j-th row of Theta corresponds to the preference vector $\\theta^{(j)}$ for the j-th user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Passing X and Theta to cofiCostFunc**\n",
    "\n",
    "We are going to use a optimize package scipy.optimize that requires using a **flattened vector** of parameters. However, in our problem tha parameters to be optimized are represented by two matrices, i.e. X and Theta. So, X and Theta must be passed to the cofiCostFunc as a **(mxn)+(u+n) vector**, called **parameters**:\n",
    "\n",
    "$${ \\left[ \\begin{matrix} { x }^{ (1) }, & ... & { x }^{ (m) }, \\end{matrix}\\begin{matrix} \\theta ^{ (1) }, & ... & \\theta ^{ (u) } \\end{matrix} \\right]  }_{ (m\\cdot n)+(u\\cdot n) }$$ \n",
    "\n",
    "However, inside the function, you can unfold the vector **parameters** and build the matrices X and Theta to compute J and the gradients according to the equations explained in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.2 Computing the cost J\n",
    "Suppose that the vector of features $x^{(i)}$ of the film i and the vector of preferences $\\theta^{(j)}$ of the user j are known, then the **estimate of the rating** of the user j for the movie i will be:\n",
    "\n",
    "$$\\widehat{y}^{(i,j)}=x^{(i)}(\\theta^{(j)})^{T}$$\n",
    "\n",
    "The error of the estimate will be the difference between the estimate of rating $\\widehat{y}^{(i,j)}$ and the real ratings $y^{(i,j)}$\n",
    "\n",
    "The **cost J** is defined as the the average of the squares of the errors plus two regularization terms:\n",
    "\n",
    "$$J=\\frac { 1 }{ 2 } \\sum _{ (i,j):r(i,j)=1 }^{  }{ \\left( { x }^{ (i) }({ \\theta  }^{ (j) })^{ T }-{ y }^{ (i,j) } \\right) ^{ 2 } } +\\quad \\frac { \\lambda  }{ 2 } \\sum _{ i=1 }^{ m }{ \\sum _{ k=1 }^{ n }{ ({ x }_{ k }^{ (i) })^{ 2 } }  } +\\frac { \\lambda  }{ 2 } \\sum _{ j=1 }^{ u }{ \\sum _{ k=1 }^{ n }{ ({ \\theta  }_{ k }^{ (j) })^{ 2 } }  } $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Task 7\n",
    "***\n",
    "Implement the cost J as a vectorized expression (recommended). For example, the estimate of ratings can be expressed as:\n",
    "\n",
    "$$\\widehat{Y}=X\\Theta^{T}$$\n",
    "\n",
    "Now, go back and **complete the cofiCostFunc code to compute the cost J**. Remeber that J is scalar value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3 Checking the cost J\n",
    "Now, you will import a data set and check the cofiCostFunc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coste:  157.31409370104396\n"
     ]
    }
   ],
   "source": [
    "# load dataset for checking\n",
    "Y=np.load('YmatrixTest.npy')\n",
    "R=np.load('RmatrixTest.npy')\n",
    "X=np.load('XmatrixTest.npy')\n",
    "Theta=np.load('ThetamatrixTest.npy')\n",
    "\n",
    "# dimension\n",
    "n_users = Y.shape[1]\n",
    "n_movies = Y.shape[0]\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# Aplanar las matrices X y Theta para crear el vector de parámetros\n",
    "parameters = np.concatenate([X.ravel(), Theta.ravel()])\n",
    "\n",
    "# Definir el parámetro de regularización\n",
    "# Debes reemplazar esto con el valor correcto de lambda que estás utilizando en tu configuración\n",
    "lambda_reg = 22.22\n",
    "\n",
    "# Calcular el costo usando la función cofiCostFunc\n",
    "cost, _ = cofiCostFunc(parameters, Y, R, n_users, n_movies, n_features, lambda_reg)\n",
    "\n",
    "# Mostrar el costo\n",
    "print('Coste: ', cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "***\n",
    "Call cofiCostFunc with lamb=0 (without regularization term) and check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of J (without regularization term) is 22.22 (it should be 22.22)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Cost J (without regularization term)\n",
    "J=0\n",
    "parameters=[]\n",
    "\n",
    "# YOUR CODE ..................................\n",
    "# call cofiCostFunc with lamb=0 (without regularization term)\n",
    "\n",
    "# Aplanar las matrices X y Theta para crear el vector de parámetros\n",
    "parameters = np.concatenate([X.ravel(), Theta.ravel()])\n",
    "\n",
    "# Llamar a cofiCostFunc con lamb = 0 (sin término de regularización)\n",
    "J, _ = cofiCostFunc(parameters, Y, R, n_users, n_movies, n_features, lamb=0)\n",
    "\n",
    "# YOUR CODE (end)..................................\n",
    "\n",
    "print('The value of J (without regularization term) is %0.2f (it should be 22.22)' % J )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "***\n",
    "Call cofiCostFunc with lamb=1.5 (with regularization term) and check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of J (with regularization term equal to 1.5) is 31.34 (it should be 31.34)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Cost J (with regularization term)\n",
    "J=0\n",
    "parameters=[]\n",
    "\n",
    "# YOUR CODE ..................................\n",
    "# call cofiCostFunc with lamb=1.5 (without regularization term)\n",
    "\n",
    "\n",
    "# Aplanar las matrices X y Theta para crear el vector de parámetros\n",
    "parameters = np.concatenate([X.ravel(), Theta.ravel()])\n",
    "\n",
    "# Llamar a cofiCostFunc con lamb = 1.5 (con término de regularización)\n",
    "J, _ = cofiCostFunc(parameters, Y, R, n_users, n_movies, n_features, lamb=1.5)\n",
    "\n",
    "\n",
    "# YOUR CODE (end)..................................\n",
    "\n",
    "print('The value of J (with regularization term equal to 1.5) is %0.2f (it should be 31.34)' % J )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.4 Computing the gradient of J\n",
    "The **gradient of J** depends on the two types of parameters, i.e. X and Theta. The corresponding equations are:\n",
    "\n",
    "$$\\frac { \\partial J }{ \\partial { \\theta  }_{ k }^{ (j) } } =\\sum _{ i:r(i,j)=1 }^{  }{ \\left( { x }^{ (i) }({ \\theta  }^{ (j) })^{ T }-{ y }^{ (i,j) } \\right) { x }_{ k }^{ (i) } } +\\lambda { \\theta  }_{ k }^{ (j) }$$\n",
    "\n",
    "$$\\frac { \\partial J }{ \\partial { x }_{ k }^{ (i) } } =\\sum _{ j:r(i,j)=1 }^{  }{ \\left( { x }^{ (i) }({ \\theta  }^{ (j) })^{ T }-{ y }^{ (i,j) } \\right) \\theta _{ k }^{ (j) } } +\\lambda { x }_{ k }^{ (i) }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Task 10\n",
    "***\n",
    "Now, go back and **complete the cofiCostFunc code to compute the gradient of J**. Remember to use vectorized operations instead of using for loops.\n",
    "\n",
    "Note that the outputs of cofiCostFunc are the cost J (scalar value) and the gradient, again a **flattened vector of the corresponding gradients of X and Theta**:\n",
    "\n",
    "$${ \\left[ \\begin{matrix} \\frac { \\partial J }{ \\partial { x }^{ (1) } } , & ... & \\frac { \\partial J }{ \\partial { x }^{ (m) } } , & \\frac { \\partial J }{ \\partial \\theta ^{ (1) } } , & ... & \\frac { \\partial J }{ \\partial \\theta ^{ (u) } }  \\end{matrix} \\right]  }_{ (m\\cdot n)+(u\\cdot n) }$$\n",
    "\n",
    "After computing both gradients, you should reshape them into a flattened vector called **gradient** that will be returned by the cofiCostFunc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Checking the gradient of J\n",
    "For the same dataset of the last poit, you will check the gradient of J computed by your cofiCostFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The above two columns you get should be very similar.\n",
      "(Left - Your Numerical Gradient, Right - Analytical Gradient)\n",
      "\n",
      "(-2.1671222630903486, -2.1671222630887312)\n",
      "(-1.869123836848452, -1.8691238368475827)\n",
      "(-0.9300152790459038, -0.9300152790452532)\n",
      "(-1.5841439076647035, -1.5841439076659005)\n",
      "(-1.188446170479196, -1.1884461704788276)\n",
      "(-0.8390474059893904, -0.8390474059899131)\n",
      "(-1.0626437899041719, -1.0626437899038597)\n",
      "(-0.5930092499539796, -0.5930092499513944)\n",
      "(-0.32522667815726436, -0.3252266781573216)\n",
      "(0.6138219467599626, 0.6138219467592629)\n",
      "(0.7703441066952976, 0.7703441066988151)\n",
      "(0.6421432611958267, 0.6421432611923157)\n",
      "(-1.461896466650181, -1.461896466651514)\n",
      "(-0.696525969954287, -0.6965259699584189)\n",
      "(-2.2256863179181963, -2.2256863179217206)\n",
      "(0.013073552138642697, 0.013073552137715801)\n",
      "(0.16204940705311088, 0.16204940705401016)\n",
      "(-0.03661503070073735, -0.03661503070342405)\n",
      "(-0.03125837838791057, -0.03125837839038152)\n",
      "(0.23852381616062956, 0.23852381616025845)\n",
      "(-0.3482475325489176, -0.3482475325542487)\n",
      "(-0.5702280951069838, -0.5702280951053349)\n",
      "(-0.2563765190322087, -0.2563765190281943)\n",
      "(-1.0080054499450597, -1.0080054499466327)\n",
      "(-0.1264470848694188, -0.12644708486970174)\n",
      "(0.352997658978893, 0.3529976589760218)\n",
      "(-0.6071345602620681, -0.6071345602651743)\n",
      "If your backpropagation implementation is correct, then \n",
      "the relative difference will be small (less than 1e-9).\n",
      "Relative Difference: 1.19976254e-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check gradients (without regularization term) by running the next function\n",
    "checkCostFunction(cofiCostFunc,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The above two columns you get should be very similar.\n",
      "(Left - Your Numerical Gradient, Right - Analytical Gradient)\n",
      "\n",
      "(-0.23208114839690097, -0.23208114839975652)\n",
      "(-0.8143033805252387, -0.814303380516763)\n",
      "(-0.6702195264329802, -0.6702195264386588)\n",
      "(0.30772342345386505, 0.3077234234538109)\n",
      "(0.9216747475093712, 0.9216747475038201)\n",
      "(0.02001694605180404, 0.020016946058665774)\n",
      "(1.358054141453735, 1.3580541414523268)\n",
      "(0.7684705299970673, 0.768470529998766)\n",
      "(0.3163403082817595, 0.3163403082795445)\n",
      "(1.1342937174996237, 1.1342937174996144)\n",
      "(1.5121186213251647, 1.5121186213235793)\n",
      "(1.3885875112418233, 1.3885875112427453)\n",
      "(0.0012647084890460292, 0.0012647084900785366)\n",
      "(0.9062907786239194, 0.9062907786332649)\n",
      "(1.0324446249443398, 1.032444624946855)\n",
      "(1.077624754404205, 1.0776247544005022)\n",
      "(1.1175909060634481, 1.1175909060637979)\n",
      "(1.048878724789759, 1.0488787247897)\n",
      "(0.78598463298718, 0.7859846329835674)\n",
      "(1.4007813719052464, 1.400781371902804)\n",
      "(0.755970458694577, 0.7559704586916994)\n",
      "(-0.4680006879498322, -0.4680006879510154)\n",
      "(-0.6334300404464699, -0.6334300404430844)\n",
      "(0.27189263594351587, 0.27189263594483365)\n",
      "(0.250004383306468, 0.2500043833041779)\n",
      "(0.949403758485623, 0.9494037584886927)\n",
      "(0.7576494670136213, 0.7576494670157607)\n",
      "If your backpropagation implementation is correct, then \n",
      "the relative difference will be small (less than 1e-9).\n",
      "Relative Difference: 2.11081421e-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check gradients (with regularization term) by running the next function\n",
    "checkCostFunction(cofiCostFunc,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3 Learning and recommendation\n",
    "Finally, you will use your cofiCostFun to make predictions using the initial Movielens dataset. Part of the python code you need is already written in the next cells. You only have to complete those lines that are explicitly required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11\n",
    "***\n",
    "Load the matrix Y and R computed in the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones son correctas:\n",
      "Dimensiones de Y: (1682, 943) - Esperadas: (1682, 943)\n",
      "Dimensiones de R: (1682, 943) - Esperadas: (1682, 943)\n",
      "Matriz Y:\n",
      "[[5. 4. 0. 0. 4.]\n",
      " [3. 0. 0. 0. 3.]\n",
      " [4. 0. 0. 0. 0.]\n",
      " [3. 0. 0. 0. 0.]\n",
      " [3. 0. 0. 0. 0.]]\n",
      "\n",
      "Matriz R:\n",
      "[[1. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Task: load matrix Y and R\n",
    "# YOUR CODE ..................................\n",
    "\n",
    "# Ruta al archivo 'u.data' en tu carpeta de trabajo de Jupyter\n",
    "file_path_ratings = 'u.data'\n",
    "\n",
    "# Leer el archivo 'u.data' y crear las matrices \"Y\" y \"R\"\n",
    "ratings_data = np.genfromtxt(file_path_ratings, delimiter='\\t', dtype=int)\n",
    "num_users = np.max(ratings_data[:, 0])\n",
    "num_movies = np.max(ratings_data[:, 1])\n",
    "\n",
    "\n",
    "\n",
    "dim_Y = (num_movies, num_users)\n",
    "dim_R = (num_movies, num_users)\n",
    "\n",
    "# Supongamos que estas son las matrices cargadas\n",
    "Y = np.load('matriz_Y.npy')\n",
    "R = np.load('matriz_R.npy')\n",
    "\n",
    "# Verificar las dimensiones de las matrices Y y R\n",
    "if Y.shape == dim_Y and R.shape == dim_R:\n",
    "    print(\"Las dimensiones son correctas:\")\n",
    "    print(f\"Dimensiones de Y: {Y.shape} - Esperadas: {dim_Y}\")\n",
    "    print(f\"Dimensiones de R: {R.shape} - Esperadas: {dim_R}\")\n",
    "else:\n",
    "    print(\"Error en las dimensiones:\")\n",
    "    print(f\"Dimensiones de Y: {Y.shape} - Esperadas: {dim_Y}\")\n",
    "    print(f\"Dimensiones de R: {R.shape} - Esperadas: {dim_R}\")\n",
    "    \n",
    "# Imprimir una muestra de las matrices Y y R\n",
    "print(\"Matriz Y:\")\n",
    "print(Y[:5, :5])  # Imprime las primeras 5 filas y 5 columnas de Y\n",
    "\n",
    "print(\"\\nMatriz R:\")\n",
    "print(R[:5, :5])  # Imprime las primeras 5 filas y 5 columnas de R\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12\n",
    "***\n",
    "* Get the number of users and movies and assign the corresponding variables n_users, n_movies.\n",
    "* Set the initial parameters (Theta, X) with random values.\n",
    "* Fold X and Theta into the variable initial_parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of features\n",
    "n_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE ..................................\n",
    "# Assuming Y and R have already been loaded\n",
    "n_movies, n_users = Y.shape\n",
    "\n",
    "# Number of features\n",
    "n_features = 100\n",
    "\n",
    "# Initialize X and Theta with random values\n",
    "X = np.random.rand(n_movies, n_features)\n",
    "Theta = np.random.rand(n_users, n_features)\n",
    "\n",
    "# Unroll parameters into a single array\n",
    "initial_parameters = np.concatenate([X.ravel(), Theta.ravel()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set the rest of the parameters and minimize the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the regularization parameter\n",
    "lamb = 10\n",
    "\n",
    "# Define a function to be minimized\n",
    "def cofiCostFunc_minimize(parameters):\n",
    "    return cofiCostFunc(parameters,Y, R, n_users, n_movies, n_features,lamb)\n",
    "\n",
    "# Set the number of iteations\n",
    "max_iter=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1682, 943)\n",
      "(1682, 943)\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 66580.046998\n",
      "         Iterations: 200\n",
      "         Function evaluations: 293\n",
      "         Gradient evaluations: 293\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(R.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Minimize the function using minimize from the package scipy.optimize and get the optimized parameters\n",
    "parameters = (minimize(cofiCostFunc_minimize, initial_parameters, method=\"CG\", jac=True,\n",
    "                       options={'maxiter': max_iter, \"disp\": True})).x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13\n",
    "***\n",
    "Get the matrix of predictions P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1682, 100)\n",
      "(943, 100)\n",
      "(1682, 943)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE ..................................\n",
    "\n",
    "# Reshape the optimized parameters back into X and Theta matrices\n",
    "X_optimized = parameters[:n_movies * n_features].reshape(n_movies, n_features)\n",
    "Theta_optimized = parameters[n_movies * n_features:].reshape(n_users, n_features)\n",
    "print(X_optimized.shape)\n",
    "print(Theta_optimized.shape)\n",
    "\n",
    "# Now, you can use X_optimized and Theta_optimized for making predictions or further analysis\n",
    "\n",
    "# Calcular la matriz de predicciones P\n",
    "P = np.dot(X_optimized, Theta_optimized.T)\n",
    "print(P.shape)\n",
    "# P ahora contiene las predicciones de calificaciones para cada par de película y usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 14\n",
    "***\n",
    "Show the titles of the top-5 predictions for the first user u=0, for those films user u did not watch: r(i,u)=0 (they will be the top-5 recommendations)\n",
    "\n",
    "#### Tips\n",
    "* You can import movies' titles using Pandas (see the first notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49               Star Wars (1977)\n",
      "99                   Fargo (1996)\n",
      "168    Wrong Trousers, The (1993)\n",
      "407         Close Shave, A (1995)\n",
      "284         Secrets & Lies (1996)\n",
      "Name: title, dtype: object\n",
      "[5.03385052 5.06223251 5.1203045  5.20062706 5.51531602]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.515316019193881"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE ..................................\n",
    "\n",
    "# import pandas\n",
    "from pandas import read_table\n",
    "# read csv file\n",
    "items = read_table('u.item',header=None,sep='|',encoding='ISO-8859-1')\n",
    "# remove collumns 2-24\n",
    "items.drop(range(2,24),axis=1, inplace=True)\n",
    "# name the columns\n",
    "items.columns = ['itemid','title']\n",
    "# show the first 5 rows of the dataframe\n",
    "items.head()\n",
    "\n",
    "# Continuando con tus variables existentes\n",
    "\n",
    "# Identificar películas no vistas por el usuario u=0\n",
    "not_watched_by_user = np.where(R[0, :] == 0)[0] # Obtiene los índices de las películas no vistas\n",
    "predictions_for_user = P[not_watched_by_user, 0]\n",
    "top_5_indices_not_watched = np.argsort(predictions_for_user)[-5:]\n",
    "top_5_movie_indices = not_watched_by_user[top_5_indices_not_watched]\n",
    "top_5_movie_titles = items.iloc[top_5_movie_indices]['title']\n",
    "\n",
    "# Mostrar los títulos y las predicciones correspondientes\n",
    "print(top_5_movie_titles)\n",
    "print(predictions_for_user[top_5_indices_not_watched])\n",
    "\n",
    "\n",
    "np.max(P[:,0])\n",
    "\n",
    "# Mostrar los títulos de las 5 mejores predicciones\n",
    "#print(top_5_movie_titles)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
